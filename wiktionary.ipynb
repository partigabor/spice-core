{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TGaSlG4Zac5a"
   },
   "source": [
    "## Wiktionary extractor\n",
    "\n",
    "### Multilingual extractions\n",
    "\n",
    "This pipeline takes an input of a txt file, that contains the data manually copied from a Wiktionary translations section. The tool will clean the data using regular expressions, and organize it in a neat csv, ready for plotting or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "path_in_wiktionary = \"data/wiktionary/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'silk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['silk-fabric.txt', 'silk-fiber.txt']\n",
      "['fabric', 'fiber']\n"
     ]
    }
   ],
   "source": [
    "# Create lists of files and senses\n",
    "list_of_files = []\n",
    "for file in os.listdir(path_in_wiktionary):\n",
    "    if file.startswith(key) and file.endswith('.txt'):\n",
    "        list_of_files.append(file)\n",
    "\n",
    "print(list_of_files)\n",
    "\n",
    "list_of_senses = []\n",
    "for file in list_of_files:\n",
    "    sense = re.sub('.*-','',file)\n",
    "    sense = re.sub('\\.txt','',sense)\n",
    "    list_of_senses.append(sense)\n",
    "\n",
    "print(list_of_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albanian</td>\n",
       "      <td>mëndafsh (sq) m</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>حَرِير‎ m (ḥarīr)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Egyptian Arabic</td>\n",
       "      <td>حرير‎ m (ḥarīr)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenian</td>\n",
       "      <td>մետաքս (hy) (metakʿs)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aromanian</td>\n",
       "      <td>mãtase f</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Walloon</td>\n",
       "      <td>soye (wa) f</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Waray-Waray</td>\n",
       "      <td>sida</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>sidan (cy) m</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Westrobothnian</td>\n",
       "      <td>selk n, siltj n</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>זײַד‎ f (zayd)</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            language                    term   sense\n",
       "0           Albanian         mëndafsh (sq) m  fabric\n",
       "1             Arabic       حَرِير‎ m (ḥarīr)  fabric\n",
       "2    Egyptian Arabic         حرير‎ m (ḥarīr)  fabric\n",
       "3           Armenian   մետաքս (hy) (metakʿs)  fabric\n",
       "4          Aromanian                mãtase f  fabric\n",
       "..               ...                     ...     ...\n",
       "122          Walloon             soye (wa) f   fiber\n",
       "123      Waray-Waray                    sida   fiber\n",
       "124            Welsh            sidan (cy) m   fiber\n",
       "125   Westrobothnian         selk n, siltj n   fiber\n",
       "126          Yiddish          זײַד‎ f (zayd)   fiber\n",
       "\n",
       "[229 rows x 3 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_key = pd.DataFrame()\n",
    "\n",
    "for file, sense in zip(list_of_files, list_of_senses):\n",
    "      # Open txt and read every line\n",
    "      txt = open(path_in_wiktionary + file, \"r\", encoding = 'utf-8')\n",
    "      lines = txt.readlines()\n",
    "      txt.close()\n",
    "\n",
    "      # Remove /n at the end of each line\n",
    "      for index, line in enumerate(lines):\n",
    "            lines[index] = line.strip()\n",
    "\n",
    "      # print(lines[:10])\n",
    "\n",
    "      # Creating a dataframe\n",
    "      df = pd.DataFrame(columns=('first', 'second'))\n",
    "      i = 0  \n",
    "      first = \"\" \n",
    "      second = \"\"  \n",
    "      for line in lines:\n",
    "            # define what are the values in columns, e.g. second colum is extracted from line:\n",
    "            second = re.sub(r\"\", \"\", line)\n",
    "            # next line data\n",
    "            df.loc[i] = [first, second]\n",
    "            i =i+1\n",
    "\n",
    "      # Replace empty cell with NaN\n",
    "      df['second'].replace('', np.nan, inplace=True)\n",
    "\n",
    "      # Drop NAs\n",
    "      df.dropna(axis=0, inplace=True)\n",
    "\n",
    "      # Reset index\n",
    "      df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "      # Drop column?\n",
    "      df.drop(['first'], axis=1, inplace=True)\n",
    "\n",
    "      # Check if contains colon?\n",
    "      df = df[df.second.str.contains(\":\", regex=True)]\n",
    "\n",
    "      # Split columns along colons \n",
    "      df = pd.DataFrame(df.second.str.split(':', 1).tolist(), columns = ['language','term'])\n",
    "\n",
    "      # Change empty to NaN\n",
    "      # df.term[df['term']==\"\"] = np.NaN\n",
    "      df.term[df['term']==\"\"] = \"TOP\"\n",
    "\n",
    "      # Fill empty cells backward (i.e fill the parent language content with value from a variant if the former is empty) # NOT A GOOD SOLUTION, FIX MANUALLY SOMEHOW\n",
    "      df['term'] =  df.term.str.extract('(.*)').fillna(method='bfill')\n",
    "\n",
    "      # Add sense\n",
    "      df['sense'] = sense\n",
    "\n",
    "      # Concatenate frames\n",
    "      df_key = pd.concat([df_key, df])\n",
    "\n",
    "df = df_key #.copy()\n",
    "print(df.shape[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort by categories\n",
    "# df['sense'] = pd.Categorical(df['sense'], list_of_senses) \n",
    "# df.sort_values(\"sense\", inplace = True)\n",
    "\n",
    "# # Sort by language\n",
    "# df = df.sort_values('language')\n",
    "\n",
    "# df.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albanian</td>\n",
       "      <td>mëndafsh (sq) m</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>حَرِير‎ m (ḥarīr)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Egyptian Arabic</td>\n",
       "      <td>حرير‎ m (ḥarīr)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Armenian</td>\n",
       "      <td>մետաքս (hy) (metakʿs)</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aromanian</td>\n",
       "      <td>mãtase f</td>\n",
       "      <td>fabric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Volapük</td>\n",
       "      <td>sadin (vo)</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Walloon</td>\n",
       "      <td>soye (wa) f</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Waray-Waray</td>\n",
       "      <td>sida</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>sidan (cy) m</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Westrobothnian</td>\n",
       "      <td>selk n, siltj n</td>\n",
       "      <td>fiber</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            language                    term   sense\n",
       "0           Albanian         mëndafsh (sq) m  fabric\n",
       "1             Arabic       حَرِير‎ m (ḥarīr)  fabric\n",
       "2    Egyptian Arabic         حرير‎ m (ḥarīr)  fabric\n",
       "3           Armenian   մետաքս (hy) (metakʿs)  fabric\n",
       "4          Aromanian                mãtase f  fabric\n",
       "..               ...                     ...     ...\n",
       "141          Volapük              sadin (vo)   fiber\n",
       "142          Walloon             soye (wa) f   fiber\n",
       "143      Waray-Waray                    sida   fiber\n",
       "144            Welsh            sidan (cy) m   fiber\n",
       "145   Westrobothnian         selk n, siltj n   fiber\n",
       "\n",
       "[146 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates(subset = ['language', 'term'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "# Reset index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filter duplicates among senses and get rid of B name if A is found. # Change subset to be more strict e.g. subset=['language', 'term']\n",
    "if len(list_of_senses) > 1:\n",
    "    df['duplicate'] = df[df.duplicated(subset=['language'], keep=False)]['sense'] == list_of_senses[1]\n",
    "    df.drop(df[df['duplicate'] == True].index, inplace=True)\n",
    "    df.drop(['duplicate'], axis=1, inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(df.shape[0])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "df['term'] = [re.sub('\\xa0', \" \", str(x)) for x in df['term']]\n",
    "\n",
    "df['term'] = [re.sub(r' m ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' m,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' m$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(bcl\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(nds\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(scn\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(ast\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(Föhr-Amrum\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s?\\(\\w\\w\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(please verify\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s+', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' ,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'^\\s', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s$', \"\", str(x)) for x in df['term']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transliteration, formatting\n",
    "df['transliteration'] = df.term.str.findall(\"(\\((\\w*\\,?\\.?\\-?\\:?\\d?\\s?ި?)+\\))\").fillna(method='ffill')\n",
    "\n",
    "df['transliteration'] = [re.sub(r\"[\\(\\)\\[\\]]\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\", ''\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"^'\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"'$\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"', '\", \", \", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"ި\", \"\", str(x)) for x in df['transliteration']]\n",
    "\n",
    "# Other\n",
    "df['transliteration'] = [re.sub(r\", taraškievica\", \"\", str(x)) for x in df['transliteration']]\n",
    "\n",
    "# Clean term of transliteration\n",
    "df['term'] = [re.sub(r\"(\\((\\w*\\,?\\.?\\-?\\:?\\d?\\s?)+\\))\", \"\", str(x)) for x in df['term']] \n",
    "df['term'] = [re.sub(r\" +,\", \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r\" *$\", \"\", str(x)) for x in df['term']] #!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skip</th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>item</th>\n",
       "      <th>group</th>\n",
       "      <th>sense</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td></td>\n",
       "      <td>Cornish</td>\n",
       "      <td>owrlin</td>\n",
       "      <td></td>\n",
       "      <td>owrlin</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td></td>\n",
       "      <td>Corsican</td>\n",
       "      <td>seta</td>\n",
       "      <td></td>\n",
       "      <td>seta</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td></td>\n",
       "      <td>Dhivehi</td>\n",
       "      <td>ފަށުި‎</td>\n",
       "      <td>faṣu</td>\n",
       "      <td>faṣu</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td></td>\n",
       "      <td>Esperanto</td>\n",
       "      <td>silko</td>\n",
       "      <td></td>\n",
       "      <td>silko</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    skip   language    term transliteration    item group  sense      source\n",
       "111         Cornish  owrlin                  owrlin        fiber  Wiktionary\n",
       "112        Corsican    seta                    seta        fiber  Wiktionary\n",
       "113         Dhivehi  ފަށުި‎            faṣu    faṣu        fiber  Wiktionary\n",
       "114       Esperanto   silko                   silko        fiber  Wiktionary"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop NA\n",
    "df = df[df.term != \"please add this translation if you can\"]\n",
    "print(df.shape[0])\n",
    "\n",
    "# Create 'item' column where everything is in\n",
    "df['item'] = df.loc[:, 'transliteration']\n",
    "df['item'] = df['item'].replace('', pd.NA).fillna(df['term'])\n",
    "\n",
    "# Create source\n",
    "df['source'] = 'Wiktionary'\n",
    "df['group'] = ''\n",
    "df['skip'] = ''\n",
    "\n",
    "# reorder\n",
    "df = df[['skip', 'language', 'term', 'transliteration', 'item', 'group', 'sense', 'source']]\n",
    "df.head(60)\n",
    "df[110:114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skip</th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>item</th>\n",
       "      <th>group</th>\n",
       "      <th>sense</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Albanian</td>\n",
       "      <td>mëndafsh</td>\n",
       "      <td></td>\n",
       "      <td>mëndafsh</td>\n",
       "      <td></td>\n",
       "      <td>fabric</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Standard Arabic</td>\n",
       "      <td>حَرِير‎</td>\n",
       "      <td>ḥarīr</td>\n",
       "      <td>ḥarīr</td>\n",
       "      <td></td>\n",
       "      <td>fabric</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Egyptian Arabic</td>\n",
       "      <td>حرير‎</td>\n",
       "      <td>ḥarīr</td>\n",
       "      <td>ḥarīr</td>\n",
       "      <td></td>\n",
       "      <td>fabric</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Eastern Armenian</td>\n",
       "      <td>մետաքս</td>\n",
       "      <td>metakʿs</td>\n",
       "      <td>metakʿs</td>\n",
       "      <td></td>\n",
       "      <td>fabric</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Aromanian</td>\n",
       "      <td>mãtase</td>\n",
       "      <td></td>\n",
       "      <td>mãtase</td>\n",
       "      <td></td>\n",
       "      <td>fabric</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td></td>\n",
       "      <td>Volapük</td>\n",
       "      <td>sadin</td>\n",
       "      <td></td>\n",
       "      <td>sadin</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td></td>\n",
       "      <td>Walloon</td>\n",
       "      <td>soye</td>\n",
       "      <td></td>\n",
       "      <td>soye</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td></td>\n",
       "      <td>Waray-Waray</td>\n",
       "      <td>sida</td>\n",
       "      <td></td>\n",
       "      <td>sida</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td></td>\n",
       "      <td>Welsh</td>\n",
       "      <td>sidan</td>\n",
       "      <td></td>\n",
       "      <td>sidan</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td></td>\n",
       "      <td>Westrobothnian</td>\n",
       "      <td>selk, siltj</td>\n",
       "      <td></td>\n",
       "      <td>selk, siltj</td>\n",
       "      <td></td>\n",
       "      <td>fiber</td>\n",
       "      <td>Wiktionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    skip          language         term transliteration         item group  \\\n",
       "0                 Albanian     mëndafsh                     mëndafsh         \n",
       "1          Standard Arabic      حَرِير‎           ḥarīr        ḥarīr         \n",
       "2          Egyptian Arabic        حرير‎           ḥarīr        ḥarīr         \n",
       "3         Eastern Armenian       մետաքս         metakʿs      metakʿs         \n",
       "4                Aromanian       mãtase                       mãtase         \n",
       "..   ...               ...          ...             ...          ...   ...   \n",
       "141                Volapük        sadin                        sadin         \n",
       "142                Walloon         soye                         soye         \n",
       "143            Waray-Waray         sida                         sida         \n",
       "144                  Welsh        sidan                        sidan         \n",
       "145         Westrobothnian  selk, siltj                  selk, siltj         \n",
       "\n",
       "      sense      source  \n",
       "0    fabric  Wiktionary  \n",
       "1    fabric  Wiktionary  \n",
       "2    fabric  Wiktionary  \n",
       "3    fabric  Wiktionary  \n",
       "4    fabric  Wiktionary  \n",
       "..      ...         ...  \n",
       "141   fiber  Wiktionary  \n",
       "142   fiber  Wiktionary  \n",
       "143   fiber  Wiktionary  \n",
       "144   fiber  Wiktionary  \n",
       "145   fiber  Wiktionary  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change languages to Glottolog name\n",
    "def glottologize():\n",
    "    df['language'] = [re.sub(r\"^Arabic$\", \"Standard Arabic\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Armenian$\", \"Eastern Armenian\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Armenian (Eastern)$\", \"Eastern Armenian\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Armenian (Western)$\", \"Western Armenian\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Bikol Central$\", \"Coastal-Naga Bikol\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Bosnian$\", \"Bosnian Standard\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Croatian$\", \"Croatian Standard\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Gaelic$\", \"Scottish Gaelic\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Greek$\", \"Modern Greek\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Greenlandic$\", \"Kalaallisut\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Hebrew$\", \"Modern Hebrew\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Kyrgyz$\", \"Kirghiz\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Luxembourgish$\", \"Luxemburgish\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Mandarin$\", \"Mandarin Chinese\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Manipuri (Meitei-Lon)$\", \"Manipuri\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Naga (Sumi)$\", \"Sumi Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Tangkhul)$\", \"North-Central Tangkhul Naga\", str(x)) for x in df['language']] # A hypoglot\n",
    "    df['language'] = [re.sub(r\"^Naga (Rengma)$\", \"Northern Rengma Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Lotha)$\", \"Lotha Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Konyak)$\", \"Konyak Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Chakhesang-Chokri)$\", \"Chokri Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Ao)$\", \"Ao Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Naga (Angami)$\", \"Angami Naga\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Norman$\", \"Anglo-Norman\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^North Frisian$\", \"Northern Frisian\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^North Sami$\", \"North Saami\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Old Armenian$\", \"Classical-Middle Armenian\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Old Church Slavonic$\", \"Church Slavic\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Old East Slavic$\", \"Old Russian\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Old Javanese$\", \"Kawi\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Ossetian$\", \"Modern Ossetic\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Punjabi$\", \"Eastern Panjabi\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^Serbian$\", \"Serbian Standard\", str(x)) for x in df['language']]\n",
    "    df['language'] = [re.sub(r\"^Serbo-Croatian$\", \"Serbian-Croatian-Bosnian\", str(x)) for x in df['language']]\n",
    "\n",
    "    df['language'] = [re.sub(r\"^West Frisian$\", \"Western Frisian\", str(x)) for x in df['language']]\n",
    "\n",
    "    return df\n",
    "\n",
    "glottologize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write\n",
    "df.to_excel(path_in_wiktionary + key + '_generated.xlsx', sheet_name='wiktionary', index=None, encoding=\"utf-8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual steps\n",
    "\n",
    "Now the manual work: Use the generated file `key_generated.xlsx` to fix, amend, append, group, and organize the names, with the addition of other sources and create a `key.xlsx` master list.\n",
    "\n",
    "Steps:\n",
    " 1. Manual check transliterations, especially Dhivehi.\n",
    " 2. Analyze and group words/names.\n",
    " 3. Mark uncertain ones for skipping with 'yes'.\n",
    "\n",
    "Recommended sources:\n",
    "* Katzer (needs serious checking)\n",
    "* WOLD\n",
    "* Max Planck databases (CLIC3, etc.)\n",
    "* others... \n",
    "\n",
    "After that, more preprocessing, cleaning, and merging with language data and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and store content of an excel file \n",
    "read_file = pd.read_excel(path_in_wiktionary + key +\".xlsx\")\n",
    "\n",
    "# Write the dataframe object into csv file\n",
    "read_file.to_csv (path_in_wiktionary + key + \".csv\", index = None, header=True)\n",
    "\n",
    "# Load in dataset\n",
    "df = pd.read_csv(path_in_wiktionary + key + \".csv\", header =[0], delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# Extract only desired columns\n",
    "selectlist = ['skip', 'language', 'term', 'transliteration', 'item', 'group']\n",
    "df = df[selectlist]\n",
    "\n",
    "print(\"Before skipping: \", df.shape[0])\n",
    "df=df[df['skip'] != \"yes\"]\n",
    "print(\"After skipping: \", df.shape[0])\n",
    "\n",
    "# # drop columns manually\n",
    "# df.drop(columns=['skip', 'literal', 'explanation', 'IPA', 'source zotero', 'notes', 'type', 'katzer', 'katzer tr', 'checked', 'reference', 'link'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIX BELOW HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_input = df.copy()\n",
    "\n",
    "# # load in datasets\n",
    "# languages=pd.read_csv(path_in_wiktionary + 'languages/languages.csv', header =[0], delimiter=',', encoding=\"utf-8\", index_col=[0])\n",
    "\n",
    "# # merge input and languages\n",
    "# df = pd.merge(df_input, languages, on=['language'])\n",
    "# print(\"Merged:\", df.shape)\n",
    "\n",
    "# #drop duplicates\n",
    "# df.drop_duplicates(subset=['language', 'term'], keep='first', inplace=True, ignore_index=True)\n",
    "# print(\"Dropping duplicates:\", df.shape)\n",
    "\n",
    "# multilingual = df\n",
    "# multilingual\n",
    "\n",
    "# #check missing ones\n",
    "# temp = pd.merge(df_input, multilingual, how='outer', suffixes=('','_y'), indicator=True)\n",
    "# missing = temp[temp['_merge']=='left_only'][df_input.columns]\n",
    "# print(\"The following terms and languages have failed to load:\")\n",
    "# print(missing)\n",
    "\n",
    "# # df = df.dropna() #OPERATIVE ONLY\n",
    "# # df = df.fillna('x')\n",
    "\n",
    "# #sort by categories, cinnamon ######## AUTOMATE ########\n",
    "# df['group'] = pd.Categorical(df['group'], [\"canela\", \"kinnamon\", \"korica\", \"qirfa\", \"darchin\", \"gui\", \"other\"]) # add categorical order here\n",
    "# df.sort_values(\"group\", inplace = True) # sort according to the categories\n",
    "\n",
    "# # #sort by categories, pepper ######## AUTOMATE ########\n",
    "# # df['group'] = pd.Categorical(df['group'], [\"pippali\", \"pigment\", \"marica\", \"hujiao\", \"other\"]) # add categorical order here\n",
    "# # df.sort_values(\"group\", inplace = True) # sort according to the categories\n",
    "\n",
    "# # create text for annotation label\n",
    "# df['text'] = df['term'] + '<br>' + df['transliteration'].astype(str) + '<br>Language: ' + df['language'] + '<br>Family: ' + df['family']\n",
    "# df['text'] = [re.sub(r\"<br>nan<br>\", \"<br>\", str(x)) for x in df['text']]\n",
    "\n",
    "# df['term'] = [re.sub(r\"\\u200e\", \"\", str(x)) for x in df['term']] #removes right to left mark\n",
    "# df['term'] = [re.sub(r\" *$\", \"\", str(x)) for x in df['term']] #!\n",
    "\n",
    "# # reindex?\n",
    "\n",
    "# # save\n",
    "# df.to_csv(path_in_wiktionary + \"multilingual/\" + key +'.csv')\n",
    "# df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sILJPbh2dRxn"
   },
   "source": [
    "### Multilingual extractions for Spices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5diFwxcT7Ed1"
   },
   "outputs": [],
   "source": [
    "key = \"cinnamon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "k98u2n06n1DA",
    "outputId": "b37d0ab2-dfc9-4aab-a655-06a393a45420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           language                                             term  sense\n",
      "0         Afrikaans                                           kaneel  spice\n",
      "1          Albanian                                   kanellë (sq) f  spice\n",
      "2           Amharic                                     ቀረፋ (ḳäräfa)  spice\n",
      "3            Arabic                               قِرْفَة‎ f (qirfa)  spice\n",
      "4   Egyptian Arabic                                  قرفة‎ f (ʾerfa)  spice\n",
      "..              ...                                              ...    ...\n",
      "88            Uzbek                            dolchin (uz), koritsa  spice\n",
      "89       Vietnamese                                         quế (vi)  spice\n",
      "90          Volapük                                           kirfat  spice\n",
      "91            Welsh                                        synamon m  spice\n",
      "92          Yiddish   צימרינג‎ m (tsimring), צימערינג‎ m (tsimering)  spice\n",
      "\n",
      "[93 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Open txt and separate every line\n",
    "txt = open(path_in_wiktionary + key + '_spice.txt', \"r\", encoding = 'utf8')\n",
    "lines = txt.readlines()\n",
    "txt.close()\n",
    "\n",
    "# Remove /n at the end of each line\n",
    "for index, line in enumerate(lines):\n",
    "      lines[index] = line.strip()\n",
    "\n",
    "# Creating a dataframe\n",
    "df = pd.DataFrame(columns=('first', 'second'))\n",
    "i = 0  \n",
    "first = \"\" \n",
    "second = \"\"  \n",
    "for line in lines:\n",
    "        #you have to kind of define what are the values in columns,for example second column includes:\n",
    "        second = re.sub(r'', \"\", line)\n",
    "        #this is how you create next line data\n",
    "        df.loc[i] = [first, second]\n",
    "        i =i+1\n",
    "\n",
    "\n",
    "df['second'].replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(['first'], axis=1, inplace=True)\n",
    "df=df[df.second.str.contains(\":\", regex=True)]\n",
    "df = pd.DataFrame(df.second.str.split(':', 1).tolist(), columns = ['language','term'])\n",
    "\n",
    "df['sense'] = 'spice'\n",
    "\n",
    "#fill empty cells backward (i.e fill the parent language content with value from a variant if the former is empty)\n",
    "df.term[df['term']==\"\"] = np.NaN\n",
    "df['term'] =  df.term.str.extract('(.*)').fillna(method='bfill')\n",
    "\n",
    "# df = df.sort_values('language')\n",
    "\n",
    "spice = df\n",
    "print(spice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2o8o0sLdX85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           language                                   term  sense\n",
      "0         Afrikaans                             kaneelboom  plant\n",
      "1            Arabic                     قِرْفَة‎ f (qirfa)  plant\n",
      "2     Hijazi Arabic                          قرفة‎ (girfa)  plant\n",
      "3   Moroccan Arabic                          قرفة‎ (qarfa)  plant\n",
      "4           Aramaic   ܕܪܨܝܢܝ‎ (dārṣīnī), ܨܝܢܕܪܓ‎ (ṣīndreḡ)  plant\n",
      "..              ...                                    ...    ...\n",
      "61             Thai                       อบเชย (òp-chəəi)  plant\n",
      "62          Tibetan                     ཤིང་ཚ (shing tsha)  plant\n",
      "63          Turkish                           tarçın ağacı  plant\n",
      "64       Vietnamese                                cây quế  plant\n",
      "65          Volapük                   kirfatep, kirfatabim  plant\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "path = path_in_wiktionary + key + '_plant.txt'\n",
    "\n",
    "if os.path.exists(path):\n",
    "\n",
    "      #open txt and seperate every line\n",
    "      df = open(path_in_wiktionary + key + '_plant.txt', \"r\", encoding = 'utf8')\n",
    "      lines = df.readlines()\n",
    "      df.close()\n",
    "\n",
    "      # remove /n at the end of each line\n",
    "      for index, line in enumerate(lines):\n",
    "            lines[index] = line.strip()\n",
    "\n",
    "      #creating a dataframe(consider u want to convert your data to 2 columns)\n",
    "      df = pd.DataFrame(columns=('first', 'second'))\n",
    "      i = 0 \n",
    "      first = \"\" \n",
    "      second = \"\"  \n",
    "      for line in lines:\n",
    "            #you have to kind of define what are the values in columns,for example second column includes:\n",
    "            second = re.sub(r'', \"\", line)\n",
    "            #this is how you create next line data\n",
    "            df.loc[i] = [first, second]\n",
    "            i =i+1\n",
    "\n",
    "      df['second'].replace('', np.nan, inplace=True)\n",
    "      df.dropna(axis=0, inplace=True)\n",
    "      df.reset_index(drop=True, inplace=True)\n",
    "      df.drop(['first'], axis=1, inplace=True)\n",
    "      df=df[df.second.str.contains(\":\", regex=True)]\n",
    "      df = pd.DataFrame(df.second.str.split(':', 1).tolist(), columns = ['language','term'])\n",
    "\n",
    "      df['sense'] = 'plant'\n",
    "\n",
    "      #fill empty cells backward (i.e fill the parent language content with value from a variant)\n",
    "      df.term[df['term']==\"\"] = np.NaN\n",
    "      df['term'] =  df.term.str.extract('(.*)').fillna(method='bfill')\n",
    "      # df = df.sort_values('language')\n",
    "\n",
    "      plant = df\n",
    "      print(plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8y4wHbQUk-5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>kaneel</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albanian</td>\n",
       "      <td>kanellë (sq) f</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amharic</td>\n",
       "      <td>ቀረፋ (ḳäräfa)</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ancient</td>\n",
       "      <td>κιννάμωμον n (kinnámōmon)</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>قِرْفَة‎ f (qirfa)</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Uzbek</td>\n",
       "      <td>dolchin (uz), koritsa</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>quế (vi)</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Volapük</td>\n",
       "      <td>kirfat</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>synamon m</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>צימרינג‎ m (tsimring), צימערינג‎ m (tsimering)</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language                                             term  sense\n",
       "0     Afrikaans                                           kaneel  spice\n",
       "1      Albanian                                   kanellë (sq) f  spice\n",
       "2       Amharic                                     ቀረፋ (ḳäräfa)  spice\n",
       "3       Ancient                        κιννάμωμον n (kinnámōmon)  spice\n",
       "4        Arabic                               قِرْفَة‎ f (qirfa)  spice\n",
       "..          ...                                              ...    ...\n",
       "104       Uzbek                            dolchin (uz), koritsa  spice\n",
       "105  Vietnamese                                         quế (vi)  spice\n",
       "106     Volapük                                           kirfat  spice\n",
       "107       Welsh                                        synamon m  spice\n",
       "108     Yiddish   צימרינג‎ m (tsimring), צימערינג‎ m (tsimering)  spice\n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concat\n",
    "frames = [spice, plant]\n",
    "df = pd.concat(frames)\n",
    "\n",
    "# sort by categories\n",
    "df['sense'] = pd.Categorical(df['sense'], [\"spice\", \"plant\"]) # add categorical order here\n",
    "df.sort_values(\"sense\", inplace = True) # sort according to the categories\n",
    "\n",
    "# sort\n",
    "df = df.sort_values('language')\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates(subset = ['language', 'term'], keep = 'first').reset_index(drop = True)\n",
    "\n",
    "# reset index\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# filter duplicates and get rid of plant name if spice name found\n",
    "df['duplicate'] = df[df.duplicated(subset=['language'], keep=False)]['sense']==\"plant\" # change subset to be more strict e.g. subset=['language', 'term']\n",
    "df.drop(df[df['duplicate'] == True].index, inplace=True)\n",
    "df.drop(['duplicate'], axis=1, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PWP4AXNdmoZr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>item</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>kaneel</td>\n",
       "      <td></td>\n",
       "      <td>kaneel</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albanian</td>\n",
       "      <td>kanellë</td>\n",
       "      <td></td>\n",
       "      <td>kanellë</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amharic</td>\n",
       "      <td>ቀረፋ</td>\n",
       "      <td>ḳäräfa</td>\n",
       "      <td>ḳäräfa</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ancient</td>\n",
       "      <td>κιννάμωμον</td>\n",
       "      <td>kinnámōmon</td>\n",
       "      <td>kinnámōmon</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Standard Arabic</td>\n",
       "      <td>قِرْفَة‎</td>\n",
       "      <td>qirfa</td>\n",
       "      <td>qirfa</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Uzbek</td>\n",
       "      <td>dolchin, koritsa</td>\n",
       "      <td></td>\n",
       "      <td>dolchin, koritsa</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>quế</td>\n",
       "      <td></td>\n",
       "      <td>quế</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Volapük</td>\n",
       "      <td>kirfat</td>\n",
       "      <td></td>\n",
       "      <td>kirfat</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Welsh</td>\n",
       "      <td>synamon</td>\n",
       "      <td></td>\n",
       "      <td>synamon</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Yiddish</td>\n",
       "      <td>צימרינג‎, צימערינג‎</td>\n",
       "      <td>tsimring, tsimering</td>\n",
       "      <td>tsimring, tsimering</td>\n",
       "      <td>spice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            language                 term      transliteration  \\\n",
       "0          Afrikaans               kaneel                        \n",
       "1           Albanian              kanellë                        \n",
       "2            Amharic                  ቀረፋ               ḳäräfa   \n",
       "3            Ancient           κιννάμωμον           kinnámōmon   \n",
       "4    Standard Arabic             قِرْفَة‎                qirfa   \n",
       "..               ...                  ...                  ...   \n",
       "104            Uzbek     dolchin, koritsa                        \n",
       "105       Vietnamese                  quế                        \n",
       "106          Volapük               kirfat                        \n",
       "107            Welsh              synamon                        \n",
       "108          Yiddish  צימרינג‎, צימערינג‎  tsimring, tsimering   \n",
       "\n",
       "                    item  sense  \n",
       "0                 kaneel  spice  \n",
       "1                kanellë  spice  \n",
       "2                 ḳäräfa  spice  \n",
       "3             kinnámōmon  spice  \n",
       "4                  qirfa  spice  \n",
       "..                   ...    ...  \n",
       "104     dolchin, koritsa  spice  \n",
       "105                  quế  spice  \n",
       "106               kirfat  spice  \n",
       "107              synamon  spice  \n",
       "108  tsimring, tsimering  spice  \n",
       "\n",
       "[109 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cleaning\n",
    "df['term'] = [re.sub(r' m ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl ', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' m,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' m$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' f$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' n$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' c$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' pl$', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(bcl\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(nds\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(scn\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(ast\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(Föhr-Amrum\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s?\\(\\w\\w\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\(please verify\\)', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s+', \" \", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r' ,', \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'^\\s', \"\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r'\\s$', \"\", str(x)) for x in df['term']]\n",
    "\n",
    "# transliteration, formatting\n",
    "df['transliteration'] = df.term.str.findall(\"(\\((\\w*\\,?\\.?\\-?\\:?\\d?\\s?)+\\))\").fillna(method='ffill')\n",
    "df['transliteration'] = [re.sub(r\"[\\(\\)\\[\\]]\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\", ''\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"^'\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"'$\", \"\", str(x)) for x in df['transliteration']]\n",
    "df['transliteration'] = [re.sub(r\"', '\", \", \", str(x)) for x in df['transliteration']]\n",
    "\n",
    "# clean term of transliteration\n",
    "df['term'] = [re.sub(r\"(\\((\\w*\\,?\\.?\\-?\\:?\\d?\\s?)+\\))\", \"\", str(x)) for x in df['term']] \n",
    "df['term'] = [re.sub(r\" +,\", \",\", str(x)) for x in df['term']]\n",
    "df['term'] = [re.sub(r\" *$\", \"\", str(x)) for x in df['term']] #!\n",
    "\n",
    "\n",
    "# other\n",
    "df['transliteration'] = [re.sub(r\", taraškievica\", \"\", str(x)) for x in df['transliteration']]\n",
    "\n",
    "# drop NA\n",
    "df = df[df.term != \"please add this translation if you can\"]\n",
    "\n",
    "# create 'item' column where everythin is in\n",
    "df['item'] = df['transliteration']\n",
    "df['item'] = df['item'].replace('', pd.NA).fillna(df['term'])\n",
    "df['source zotero'] = 'Wiktionary'\n",
    "\n",
    "# reorder\n",
    "df = df[['language', 'term', 'transliteration', 'item', 'sense']]\n",
    "\n",
    "# Change languages to glottolog name\n",
    "df['language'] = [re.sub(r\"^Arabic$\", \"Standard Arabic\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Mandarin$\", \"Mandarin Chinese\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Old Armenian$\", \"Classical-Middle Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Croatian$\", \"Croatian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Serbian$\", \"Serbian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Bosnian$\", \"Bosnian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Serbo-Croatian$\", \"Serbian-Croatian-Bosnian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Gaelic$\", \"Scottish Gaelic\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Greek$\", \"Modern Greek\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Punjabi$\", \"Eastern Panjabi\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Norman$\", \"Anglo-Norman\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Bikol Central$\", \"Coastal-Naga Bikol\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Armenian (Eastern)$\", \"Eastern Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Armenian (Western)$\", \"Western Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Manipuri (Meitei-Lon)$\", \"Manipuri\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Sumi)$\", \"Sumi Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Tangkhul)$\", \"North-Central Tangkhul Naga\", str(x)) for x in df['language']] # A hypoglot\n",
    "df['language'] = [re.sub(r\"^Naga (Rengma)$\", \"Northern Rengma Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Lotha)$\", \"Lotha Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Konyak)$\", \"Konyak Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Chakhesang-Chokri)$\", \"Chokri Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Ao)$\", \"Ao Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Angami)$\", \"Angami Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Kyrgyz$\", \"Kirghiz\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Hebrew$\", \"Modern Hebrew\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Northern Sami$\", \"North Sami\", str(x)) for x in df['language']]\n",
    "\n",
    "\n",
    "\n",
    "#write\n",
    "df.to_excel(path_in_wiktionary + key + '_generated.xlsx', sheet_name='wiktionary', index=None, encoding=\"utf-8\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the manual work: Use `spice_out.xlsx` to fix, amend, append, group, and organize the names, with the addition of other sources and create a `spice.xlsx` master list.\n",
    "\n",
    "Recommended sources:\n",
    "* Katzer (needs serious checking)\n",
    "* WOLD\n",
    "* Max Planck databases (CLIC3, etc.)\n",
    "* others... \n",
    "\n",
    "After that, more preprocessing, cleaning, and merging with language data and coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before skipping:  (162, 6)\n",
      "After skipping:  (148, 6)\n",
      "Merged: (155, 16)\n",
      "Dropping duplicates: (148, 16)\n",
      "The following terms and languages have failed to load:\n",
      "Empty DataFrame\n",
      "Columns: [skip, language, term, transliteration, item, group]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skip</th>\n",
       "      <th>language</th>\n",
       "      <th>term</th>\n",
       "      <th>transliteration</th>\n",
       "      <th>item</th>\n",
       "      <th>group</th>\n",
       "      <th>iso</th>\n",
       "      <th>glcode</th>\n",
       "      <th>level</th>\n",
       "      <th>branch</th>\n",
       "      <th>family</th>\n",
       "      <th>macroarea</th>\n",
       "      <th>country</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>from</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afrikaans</td>\n",
       "      <td>kaneel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaneel</td>\n",
       "      <td>canela</td>\n",
       "      <td>afr</td>\n",
       "      <td>afri1274</td>\n",
       "      <td>language</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Africa</td>\n",
       "      <td>ZA</td>\n",
       "      <td>-31.00000</td>\n",
       "      <td>22.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>kaneel&lt;br&gt;Language: Afrikaans&lt;br&gt;Family: Indo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Estonian</td>\n",
       "      <td>kaneel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaneel</td>\n",
       "      <td>canela</td>\n",
       "      <td>est</td>\n",
       "      <td>esto1258</td>\n",
       "      <td>language</td>\n",
       "      <td>Finnic</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>EE</td>\n",
       "      <td>59.00000</td>\n",
       "      <td>26.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>kaneel&lt;br&gt;Language: Estonian&lt;br&gt;Family: Uralic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Faroese</td>\n",
       "      <td>kanel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kanel</td>\n",
       "      <td>canela</td>\n",
       "      <td>fao</td>\n",
       "      <td>faro1244</td>\n",
       "      <td>language</td>\n",
       "      <td>Germanic</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>DK</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>-7.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>kanel&lt;br&gt;Language: Faroese&lt;br&gt;Family: Indo-Eur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>kaneli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaneli</td>\n",
       "      <td>canela</td>\n",
       "      <td>fin</td>\n",
       "      <td>finn1318</td>\n",
       "      <td>language</td>\n",
       "      <td>Finnic</td>\n",
       "      <td>Uralic</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>FI</td>\n",
       "      <td>62.00000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>kaneli&lt;br&gt;Language: Finnish&lt;br&gt;Family: Uralic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>French</td>\n",
       "      <td>cannelle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cannelle</td>\n",
       "      <td>canela</td>\n",
       "      <td>fra</td>\n",
       "      <td>stan1290</td>\n",
       "      <td>language</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Indo-European</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>CH FR</td>\n",
       "      <td>48.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>cannelle&lt;br&gt;Language: French&lt;br&gt;Family: Indo-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Sumi Naga</td>\n",
       "      <td>losani, akusa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>losani, akusa</td>\n",
       "      <td>other</td>\n",
       "      <td>nsm</td>\n",
       "      <td>sumi1235</td>\n",
       "      <td>language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>IN</td>\n",
       "      <td>25.99960</td>\n",
       "      <td>94.42350</td>\n",
       "      <td>glot</td>\n",
       "      <td>losani, akusa&lt;br&gt;Language: Sumi Naga&lt;br&gt;Family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brunei Malay</td>\n",
       "      <td>kayu manis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kayu manis</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brun1243</td>\n",
       "      <td>dialect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>Papunesia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.53000</td>\n",
       "      <td>114.72000</td>\n",
       "      <td>glot</td>\n",
       "      <td>kayu manis&lt;br&gt;Language: Brunei Malay&lt;br&gt;Family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yoruba</td>\n",
       "      <td>eso igi gbigbẹ oloorun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eso igi gbigbẹ oloorun</td>\n",
       "      <td>other</td>\n",
       "      <td>yor</td>\n",
       "      <td>yoru1245</td>\n",
       "      <td>language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic-Congo</td>\n",
       "      <td>Africa</td>\n",
       "      <td>BJ NG</td>\n",
       "      <td>7.15345</td>\n",
       "      <td>3.67225</td>\n",
       "      <td>glot</td>\n",
       "      <td>eso igi gbigbẹ oloorun&lt;br&gt;Language: Yoruba&lt;br&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lao</td>\n",
       "      <td>ອົບເຊຍ</td>\n",
       "      <td>obsey</td>\n",
       "      <td>obsey</td>\n",
       "      <td>other</td>\n",
       "      <td>lao</td>\n",
       "      <td>laoo1244</td>\n",
       "      <td>language</td>\n",
       "      <td>Kam-Tai</td>\n",
       "      <td>Tai-Kadai</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>LA TH</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>103.00000</td>\n",
       "      <td>wals1</td>\n",
       "      <td>ອົບເຊຍ&lt;br&gt;obsey&lt;br&gt;Language: Lao&lt;br&gt;Family: Ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lotha Naga</td>\n",
       "      <td>xsangsuru</td>\n",
       "      <td>NaN</td>\n",
       "      <td>xsangsuru</td>\n",
       "      <td>other</td>\n",
       "      <td>njh</td>\n",
       "      <td>loth1237</td>\n",
       "      <td>language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td>Eurasia</td>\n",
       "      <td>IN</td>\n",
       "      <td>26.01396</td>\n",
       "      <td>94.04355</td>\n",
       "      <td>glot</td>\n",
       "      <td>xsangsuru&lt;br&gt;Language: Lotha Naga&lt;br&gt;Family: S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    skip      language                    term transliteration  \\\n",
       "0    NaN     Afrikaans                  kaneel             NaN   \n",
       "36   NaN      Estonian                  kaneel             NaN   \n",
       "37   NaN       Faroese                   kanel             NaN   \n",
       "38   NaN       Finnish                  kaneli             NaN   \n",
       "39   NaN        French                cannelle             NaN   \n",
       "..   ...           ...                     ...             ...   \n",
       "121  NaN     Sumi Naga           losani, akusa             NaN   \n",
       "12   NaN  Brunei Malay              kayu manis             NaN   \n",
       "146  NaN        Yoruba  eso igi gbigbẹ oloorun             NaN   \n",
       "71   NaN           Lao                  ອົບເຊຍ           obsey   \n",
       "75   NaN    Lotha Naga               xsangsuru             NaN   \n",
       "\n",
       "                       item   group  iso    glcode     level    branch  \\\n",
       "0                    kaneel  canela  afr  afri1274  language  Germanic   \n",
       "36                   kaneel  canela  est  esto1258  language    Finnic   \n",
       "37                    kanel  canela  fao  faro1244  language  Germanic   \n",
       "38                   kaneli  canela  fin  finn1318  language    Finnic   \n",
       "39                 cannelle  canela  fra  stan1290  language   Romance   \n",
       "..                      ...     ...  ...       ...       ...       ...   \n",
       "121           losani, akusa   other  nsm  sumi1235  language       NaN   \n",
       "12               kayu manis   other  NaN  brun1243   dialect       NaN   \n",
       "146  eso igi gbigbẹ oloorun   other  yor  yoru1245  language       NaN   \n",
       "71                    obsey   other  lao  laoo1244  language   Kam-Tai   \n",
       "75                xsangsuru   other  njh  loth1237  language       NaN   \n",
       "\n",
       "             family  macroarea country       lat        lon   from  \\\n",
       "0     Indo-European     Africa      ZA -31.00000   22.00000  wals1   \n",
       "36           Uralic    Eurasia      EE  59.00000   26.00000  wals1   \n",
       "37    Indo-European    Eurasia      DK  62.00000   -7.00000  wals1   \n",
       "38           Uralic    Eurasia      FI  62.00000   25.00000  wals1   \n",
       "39    Indo-European    Eurasia   CH FR  48.00000    2.00000  wals1   \n",
       "..              ...        ...     ...       ...        ...    ...   \n",
       "121    Sino-Tibetan    Eurasia      IN  25.99960   94.42350   glot   \n",
       "12     Austronesian  Papunesia     NaN   4.53000  114.72000   glot   \n",
       "146  Atlantic-Congo     Africa   BJ NG   7.15345    3.67225   glot   \n",
       "71        Tai-Kadai    Eurasia   LA TH  18.00000  103.00000  wals1   \n",
       "75     Sino-Tibetan    Eurasia      IN  26.01396   94.04355   glot   \n",
       "\n",
       "                                                  text  \n",
       "0    kaneel<br>Language: Afrikaans<br>Family: Indo-...  \n",
       "36      kaneel<br>Language: Estonian<br>Family: Uralic  \n",
       "37   kanel<br>Language: Faroese<br>Family: Indo-Eur...  \n",
       "38       kaneli<br>Language: Finnish<br>Family: Uralic  \n",
       "39   cannelle<br>Language: French<br>Family: Indo-E...  \n",
       "..                                                 ...  \n",
       "121  losani, akusa<br>Language: Sumi Naga<br>Family...  \n",
       "12   kayu manis<br>Language: Brunei Malay<br>Family...  \n",
       "146  eso igi gbigbẹ oloorun<br>Language: Yoruba<br>...  \n",
       "71   ອົບເຊຍ<br>obsey<br>Language: Lao<br>Family: Ta...  \n",
       "75   xsangsuru<br>Language: Lotha Naga<br>Family: S...  \n",
       "\n",
       "[148 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and store content of an excel file \n",
    "read_file = pd.read_excel(path_in_wiktionary + key +\".xlsx\")\n",
    "\n",
    "# Write the dataframe object into csv file\n",
    "read_file.to_csv (path_in_wiktionary + key + \".csv\", index = None, header=True)\n",
    "\n",
    "# Load in dataset\n",
    "df=pd.read_csv(path_in_wiktionary + key + \".csv\", header =[0], delimiter=',', encoding=\"utf-8\")\n",
    "\n",
    "# extract only desired columns\n",
    "selectlist = ['skip', 'language', 'term', 'transliteration', 'item', 'group']\n",
    "df = df[selectlist]\n",
    "\n",
    "print(\"Before skipping: \", df.shape)\n",
    "df=df[df['skip'] != \"yes\"]\n",
    "print(\"After skipping: \", df.shape)\n",
    "\n",
    "# # drop columns manually\n",
    "# df.drop(columns=['skip', 'literal', 'explanation', 'IPA', 'source zotero', 'notes', 'type', 'katzer', 'katzer tr', 'checked', 'reference', 'link'], inplace=True)\n",
    "\n",
    "# Change languages to glottolog name\n",
    "df['language'] = [re.sub(r\"^Arabic$\", \"Standard Arabic\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Mandarin$\", \"Mandarin Chinese\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Old Armenian$\", \"Classical-Middle Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Croatian$\", \"Croatian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Serbian$\", \"Serbian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Bosnian$\", \"Bosnian Standard\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Serbo-Croatian$\", \"Serbian-Croatian-Bosnian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Gaelic$\", \"Scottish Gaelic\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Greek$\", \"Modern Greek\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Punjabi$\", \"Eastern Panjabi\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Norman$\", \"Anglo-Norman\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Bikol Central$\", \"Coastal-Naga Bikol\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Armenian (Eastern)$\", \"Eastern Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Armenian (Western)$\", \"Western Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Manipuri (Meitei-Lon)$\", \"Manipuri\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Sumi)$\", \"Sumi Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Tangkhul)$\", \"North-Central Tangkhul Naga\", str(x)) for x in df['language']] # A hypoglot\n",
    "df['language'] = [re.sub(r\"^Naga (Rengma)$\", \"Northern Rengma Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Lotha)$\", \"Lotha Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Konyak)$\", \"Konyak Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Chakhesang-Chokri)$\", \"Chokri Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Ao)$\", \"Ao Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Naga (Angami)$\", \"Angami Naga\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Kyrgyz$\", \"Kirghiz\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Hebrew$\", \"Modern Hebrew\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^North Sami$\", \"North Saami\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Greenlandic$\", \"Kalaallisut\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^West Frisian$\", \"Western Frisian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Old Javanese$\", \"Kawi\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Old Church Slavonic$\", \"Church Slavic\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^North Frisian$\", \"Northern Frisian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Luxembourgish$\", \"Luxemburgish\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Armenian$\", \"Eastern Armenian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Old East Slavic$\", \"Old Russian\", str(x)) for x in df['language']]\n",
    "df['language'] = [re.sub(r\"^Ossetian$\", \"Modern Ossetic\", str(x)) for x in df['language']]\n",
    "\n",
    "df_input = df\n",
    "\n",
    "# load in datasets\n",
    "languages=pd.read_csv(path_in_wiktionary + 'languages/languages.csv', header =[0], delimiter=',', encoding=\"utf-8\", index_col=[0])\n",
    "\n",
    "# merge input and languages\n",
    "df = pd.merge(df_input, languages, on=['language'])\n",
    "print(\"Merged:\", df.shape)\n",
    "\n",
    "#drop duplicates\n",
    "df.drop_duplicates(subset=['language', 'term'], keep='first', inplace=True, ignore_index=True)\n",
    "print(\"Dropping duplicates:\", df.shape)\n",
    "\n",
    "multilingual = df\n",
    "multilingual\n",
    "\n",
    "#check missing ones\n",
    "temp = pd.merge(df_input, multilingual, how='outer', suffixes=('','_y'), indicator=True)\n",
    "missing = temp[temp['_merge']=='left_only'][df_input.columns]\n",
    "print(\"The following terms and languages have failed to load:\")\n",
    "print(missing)\n",
    "\n",
    "# df = df.dropna() #OPERATIVE ONLY\n",
    "# df = df.fillna('x')\n",
    "\n",
    "#sort by categories, cinnamon ######## AUTOMATE ########\n",
    "df['group'] = pd.Categorical(df['group'], [\"canela\", \"kinnamon\", \"korica\", \"qirfa\", \"darchin\", \"gui\", \"other\"]) # add categorical order here\n",
    "df.sort_values(\"group\", inplace = True) # sort according to the categories\n",
    "\n",
    "# #sort by categories, pepper ######## AUTOMATE ########\n",
    "# df['group'] = pd.Categorical(df['group'], [\"pippali\", \"pigment\", \"marica\", \"hujiao\", \"other\"]) # add categorical order here\n",
    "# df.sort_values(\"group\", inplace = True) # sort according to the categories\n",
    "\n",
    "# create text for annotation label\n",
    "df['text'] = df['term'] + '<br>' + df['transliteration'].astype(str) + '<br>Language: ' + df['language'] + '<br>Family: ' + df['family']\n",
    "df['text'] = [re.sub(r\"<br>nan<br>\", \"<br>\", str(x)) for x in df['text']]\n",
    "\n",
    "df['term'] = [re.sub(r\"\\u200e\", \"\", str(x)) for x in df['term']] #removes right to left mark\n",
    "df['term'] = [re.sub(r\" *$\", \"\", str(x)) for x in df['term']] #!\n",
    "\n",
    "# reindex?\n",
    "\n",
    "# save\n",
    "df.to_csv(path_in_wiktionary + \"multilingual/\" + key +'.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18c4d285bf73f8d33795481156cb8e20c5329867a6af52097d4f49f8abbf9900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
